{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-12T03:19:40.224949Z","iopub.execute_input":"2022-09-12T03:19:40.225373Z","iopub.status.idle":"2022-09-12T03:19:40.243689Z","shell.execute_reply.started":"2022-09-12T03:19:40.225341Z","shell.execute_reply":"2022-09-12T03:19:40.242731Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/potentialtalents/potential-talents - Aspiring human resources - seeking human resources.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:40.586078Z","iopub.execute_input":"2022-09-12T03:19:40.586490Z","iopub.status.idle":"2022-09-12T03:19:40.597686Z","shell.execute_reply.started":"2022-09-12T03:19:40.586460Z","shell.execute_reply":"2022-09-12T03:19:40.596460Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"data['input'] = \"Aspiring Human Resources seeking human resources\"","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:40.884205Z","iopub.execute_input":"2022-09-12T03:19:40.884618Z","iopub.status.idle":"2022-09-12T03:19:40.890955Z","shell.execute_reply.started":"2022-09-12T03:19:40.884582Z","shell.execute_reply":"2022-09-12T03:19:40.890079Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from nltk import word_tokenize, pos_tag\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nimport re \nimport string \ndef removestopwords(text):\n    stop_words = set(stopwords.words('english'))\n#     print(stop_words)\n    text = re.sub(r'[^\\w\\s]', \" \", text)\n    text  = [word for word in text.split() if word not in stop_words]\n    \n    return text    \n\ndef lemmatization(text):\n    words = removestopwords(text)\n#     print(words)\n#     words = word_tokenize(words)\n#     word_tagged = pos_tag(words)\n#     print( word_tagged)\n    lemmatizer = WordNetLemmatizer()\n    text = \" \".join([lemmatizer.lemmatize(word) for word in words])\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:41.365762Z","iopub.execute_input":"2022-09-12T03:19:41.366417Z","iopub.status.idle":"2022-09-12T03:19:41.374412Z","shell.execute_reply.started":"2022-09-12T03:19:41.366378Z","shell.execute_reply":"2022-09-12T03:19:41.373269Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('omw-1.4')","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:41.531330Z","iopub.execute_input":"2022-09-12T03:19:41.531958Z","iopub.status.idle":"2022-09-12T03:19:41.599515Z","shell.execute_reply.started":"2022-09-12T03:19:41.531913Z","shell.execute_reply":"2022-09-12T03:19:41.598320Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"data['job_title'] = data['job_title'].apply(lambda x: lemmatization(x))\ndata['job_title'] ","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:41.832786Z","iopub.execute_input":"2022-09-12T03:19:41.833720Z","iopub.status.idle":"2022-09-12T03:19:41.867430Z","shell.execute_reply.started":"2022-09-12T03:19:41.833682Z","shell.execute_reply":"2022-09-12T03:19:41.866274Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# **word2vec**","metadata":{}},{"cell_type":"code","source":"import nltk\nimport gensim\nfrom gensim.models import Word2Vec\ntokens = data['job_title'].apply(lambda x: nltk.word_tokenize(x))\nw2v_model = Word2Vec(tokens,\n                     min_count=1,\n                     window=10,\n                     vector_size=250,\n                     alpha=0.03, \n                     min_alpha=0.0007,\n                     workers = 4,\n                     seed = 42)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:42.421555Z","iopub.execute_input":"2022-09-12T03:19:42.421951Z","iopub.status.idle":"2022-09-12T03:19:42.466988Z","shell.execute_reply.started":"2022-09-12T03:19:42.421919Z","shell.execute_reply":"2022-09-12T03:19:42.466137Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from scipy import spatial\n    \nindextokey_set = set(w2v_model.wv.index_to_key)\ndef avg_feature_vector(sentence, w2v_model, num_features, index2word_set):\n    words = sentence.split()\n    feature_vec = np.zeros((num_features, ), dtype='float32')\n    n_words = 0\n    for word in words:\n            if word in index2word_set:\n                n_words += 1\n                feature_vec = np.add(feature_vec, w2v_model.wv[word])\n                \n            if (n_words > 0):\n                feature_vec = np.divide(feature_vec, n_words)\n    return feature_vec  ","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:42.764381Z","iopub.execute_input":"2022-09-12T03:19:42.764802Z","iopub.status.idle":"2022-09-12T03:19:42.772321Z","shell.execute_reply.started":"2022-09-12T03:19:42.764768Z","shell.execute_reply":"2022-09-12T03:19:42.771335Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"score1 = []\nfor sentence in data['job_title']:\n    s1_afv = avg_feature_vector(sentence, w2v_model, num_features=250, index2word_set=indextokey_set)     \n    score1.append(s1_afv)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:43.089165Z","iopub.execute_input":"2022-09-12T03:19:43.090173Z","iopub.status.idle":"2022-09-12T03:19:43.098717Z","shell.execute_reply.started":"2022-09-12T03:19:43.090124Z","shell.execute_reply":"2022-09-12T03:19:43.097728Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"score2 = []\nfor sentence in data['input']:\n    s2_afv = [avg_feature_vector(sentence, w2v_model, num_features=250, index2word_set=indextokey_set)]\n    score2.append(s2_afv)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:43.411726Z","iopub.execute_input":"2022-09-12T03:19:43.412134Z","iopub.status.idle":"2022-09-12T03:19:43.420507Z","shell.execute_reply.started":"2022-09-12T03:19:43.412101Z","shell.execute_reply":"2022-09-12T03:19:43.419510Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# the output is Cosine simlilarity with word2vec word embedding \nsim_word2vec = []\nfor i in range(len(score1)):\n    sim = 1 - spatial.distance.cosine(score1[i],score2[i])\n    sim_word2vec.append(sim)\nprint(sim_word2vec)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:43.719678Z","iopub.execute_input":"2022-09-12T03:19:43.720426Z","iopub.status.idle":"2022-09-12T03:19:43.738179Z","shell.execute_reply.started":"2022-09-12T03:19:43.720384Z","shell.execute_reply":"2022-09-12T03:19:43.737140Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"# **TFIDF**","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\ndef cosine_sim(text1, text2):\n    tfidf = vectorizer.fit_transform([text1, text2])\n    return ((tfidf * tfidf.T).A)[0,1]","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:44.361505Z","iopub.execute_input":"2022-09-12T03:19:44.361890Z","iopub.status.idle":"2022-09-12T03:19:44.367893Z","shell.execute_reply.started":"2022-09-12T03:19:44.361858Z","shell.execute_reply":"2022-09-12T03:19:44.366907Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# the output is Cosine simlilarity with tfidf vectorizer \nsim_tfidf = []\nfor i in range(len(data['job_title'])):\n    score = cosine_sim(data['job_title'][i], data['input'][i])\n    sim_tfidf.append(score)\nprint(sim_tfidf)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:44.689564Z","iopub.execute_input":"2022-09-12T03:19:44.690247Z","iopub.status.idle":"2022-09-12T03:19:44.858386Z","shell.execute_reply.started":"2022-09-12T03:19:44.690206Z","shell.execute_reply":"2022-09-12T03:19:44.857255Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"# **Glove**","metadata":{}},{"cell_type":"code","source":"# !wget http://nlp.stanford.edu/data/glove.6B.zip\n# !unzip glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:45.354654Z","iopub.execute_input":"2022-09-12T03:19:45.355113Z","iopub.status.idle":"2022-09-12T03:19:45.359737Z","shell.execute_reply.started":"2022-09-12T03:19:45.355073Z","shell.execute_reply":"2022-09-12T03:19:45.358676Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"GLOVE_EMB = '../input/glove6b300dtxt/glove.6B.300d.txt'\nEMBEDDING_DIM = 300","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:45.652314Z","iopub.execute_input":"2022-09-12T03:19:45.653370Z","iopub.status.idle":"2022-09-12T03:19:45.657493Z","shell.execute_reply.started":"2022-09-12T03:19:45.653329Z","shell.execute_reply":"2022-09-12T03:19:45.656572Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(data['job_title'])\n\nword_index = tokenizer.word_index\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Vocabulary Size :\", vocab_size)\nword_index.keys()","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:46.036223Z","iopub.execute_input":"2022-09-12T03:19:46.036620Z","iopub.status.idle":"2022-09-12T03:19:46.048346Z","shell.execute_reply.started":"2022-09-12T03:19:46.036586Z","shell.execute_reply":"2022-09-12T03:19:46.047293Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"embeddings_index = {}\n\nf = open(GLOVE_EMB)\nfor line in f:\n    values = line.split()\n    word = value = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' %len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:19:46.319157Z","iopub.execute_input":"2022-09-12T03:19:46.319789Z","iopub.status.idle":"2022-09-12T03:20:13.180399Z","shell.execute_reply.started":"2022-09-12T03:19:46.319755Z","shell.execute_reply":"2022-09-12T03:20:13.178315Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.183570Z","iopub.execute_input":"2022-09-12T03:20:13.184016Z","iopub.status.idle":"2022-09-12T03:20:13.194080Z","shell.execute_reply.started":"2022-09-12T03:20:13.183964Z","shell.execute_reply":"2022-09-12T03:20:13.193056Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"indextokey_set = set(word_index.keys())\nprint(indextokey_set)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.195782Z","iopub.execute_input":"2022-09-12T03:20:13.196142Z","iopub.status.idle":"2022-09-12T03:20:13.204903Z","shell.execute_reply.started":"2022-09-12T03:20:13.196112Z","shell.execute_reply":"2022-09-12T03:20:13.203934Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"def avg_feature_vector_glove(sentence,embedding_matrix, num_features, index2word_set):\n    words = sentence.split()\n    feature_vec = np.zeros((num_features, ), dtype='float32')\n    n_words = 0\n    for word in words:\n            if word in index2word_set:\n                n_words += 1\n                feature_vec = np.add(feature_vec,embedding_matrix[word_index[word]]) \n            if (n_words > 0):\n                feature_vec = np.divide(feature_vec, n_words)\n    return feature_vec  ","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.207373Z","iopub.execute_input":"2022-09-12T03:20:13.207976Z","iopub.status.idle":"2022-09-12T03:20:13.221464Z","shell.execute_reply.started":"2022-09-12T03:20:13.207944Z","shell.execute_reply":"2022-09-12T03:20:13.220352Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"score_1 = []\nfor sentence in data['job_title']:\n    s1_afv = avg_feature_vector_glove(sentence,embedding_matrix,num_features=300, index2word_set=indextokey_set)     \n    score_1.append(s1_afv)\nprint(len(score_1))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.222930Z","iopub.execute_input":"2022-09-12T03:20:13.223543Z","iopub.status.idle":"2022-09-12T03:20:13.240850Z","shell.execute_reply.started":"2022-09-12T03:20:13.223508Z","shell.execute_reply":"2022-09-12T03:20:13.239481Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"score_2 = []\nfor sentence in data['input']:\n    s1_afv = avg_feature_vector_glove(sentence,embedding_matrix, num_features=300, index2word_set=indextokey_set)     \n    score_2.append(s1_afv)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.242297Z","iopub.execute_input":"2022-09-12T03:20:13.243202Z","iopub.status.idle":"2022-09-12T03:20:13.253776Z","shell.execute_reply.started":"2022-09-12T03:20:13.243166Z","shell.execute_reply":"2022-09-12T03:20:13.252506Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# the output is Cosine simlilarity with word2vec word embedding \nsim_glove = []\nfor i in range(len(score1)):\n    sim = 1 - spatial.distance.cosine(score_1[i],score_2[i])\n    sim_glove.append(sim)\nprint(sim_glove)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.255527Z","iopub.execute_input":"2022-09-12T03:20:13.256188Z","iopub.status.idle":"2022-09-12T03:20:13.271195Z","shell.execute_reply.started":"2022-09-12T03:20:13.256155Z","shell.execute_reply":"2022-09-12T03:20:13.269818Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"# **Cosine Similarity**","metadata":{}},{"cell_type":"code","source":"# Cosine Similarity with word2vec, tfidf, and glove embedding \nresult_similarity = []\nfor i in range(len(sim_word2vec)):\n    score_mean = (sim_word2vec[i]+sim_tfidf[i]+sim_glove[i])/3\n    result_similarity.append(score_mean)\nprint(result_similarity)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.273268Z","iopub.execute_input":"2022-09-12T03:20:13.274126Z","iopub.status.idle":"2022-09-12T03:20:13.282072Z","shell.execute_reply.started":"2022-09-12T03:20:13.274077Z","shell.execute_reply":"2022-09-12T03:20:13.280953Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"data['result_similarity'] = result_similarity","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.284206Z","iopub.execute_input":"2022-09-12T03:20:13.284667Z","iopub.status.idle":"2022-09-12T03:20:13.295051Z","shell.execute_reply.started":"2022-09-12T03:20:13.284623Z","shell.execute_reply":"2022-09-12T03:20:13.293895Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"data['result_similarity']","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.300817Z","iopub.execute_input":"2022-09-12T03:20:13.303156Z","iopub.status.idle":"2022-09-12T03:20:13.314508Z","shell.execute_reply.started":"2022-09-12T03:20:13.303115Z","shell.execute_reply":"2022-09-12T03:20:13.313533Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# cut the connection variable as 1,2,3,4, the larger the higher rank \ndata['connection'] = data['connection'].str.split('+').str[0]\ndata['connection'] = data['connection'].astype(int)\nlist = data['connection'].tolist()\nlist.sort()\n# print(list)\ndata['connection'] = pd.cut(data['connection'],[0,40,200,499,600],labels=[1,2,3,4]) \ndata['connection'] = data['connection'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.316019Z","iopub.execute_input":"2022-09-12T03:20:13.316597Z","iopub.status.idle":"2022-09-12T03:20:13.331486Z","shell.execute_reply.started":"2022-09-12T03:20:13.316563Z","shell.execute_reply":"2022-09-12T03:20:13.330138Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# one hot encoding location variable\ndum_key = pd.get_dummies(data['location'])\ndata = data.drop('location', 1)\ndata = pd.concat([data,dum_key],axis=1)\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.332863Z","iopub.execute_input":"2022-09-12T03:20:13.333666Z","iopub.status.idle":"2022-09-12T03:20:13.364292Z","shell.execute_reply.started":"2022-09-12T03:20:13.333629Z","shell.execute_reply":"2022-09-12T03:20:13.363186Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# cut the result_similarity variable as 1-10, the larger the higher rank \ndata['result_similarity_bin'] = pd.cut(data['result_similarity'],[0,0.12,0.18,0.24,0.3,0.36,0.42,0.48,0.54,0.6,0.66],labels=[1,2,3,4,5,6,7,8,9,10])\ndata['result_similarity_bin']","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.372338Z","iopub.execute_input":"2022-09-12T03:20:13.373437Z","iopub.status.idle":"2022-09-12T03:20:13.395715Z","shell.execute_reply.started":"2022-09-12T03:20:13.373382Z","shell.execute_reply":"2022-09-12T03:20:13.394383Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.417938Z","iopub.execute_input":"2022-09-12T03:20:13.419187Z","iopub.status.idle":"2022-09-12T03:20:13.428190Z","shell.execute_reply.started":"2022-09-12T03:20:13.419139Z","shell.execute_reply":"2022-09-12T03:20:13.426917Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# This function is writen for assign the result_similarity column 0 or 1 \ndef Starcandidate(data,col1,col2,text):\n    #select the candidate job title which match the engine query \n    data_star = data.loc[data[col1].str.contains(text)]\n    data_star[col2] =1\n#     print(data_star[col2])\n    data_remining = data.loc[~data[col1].str.contains(text)]\n#     print( data_remining)\n    for value in data_remining[col2].values:\n        if value >=0.5:\n             data_remining[col2] = 1\n        else:  data_remining[col2] =0 \n    data = pd.concat([data_star,data_remining])\n    return data\n         \n    \n        \n    \n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.429805Z","iopub.execute_input":"2022-09-12T03:20:13.430187Z","iopub.status.idle":"2022-09-12T03:20:13.438226Z","shell.execute_reply.started":"2022-09-12T03:20:13.430144Z","shell.execute_reply":"2022-09-12T03:20:13.437022Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"data = Starcandidate(data,'job_title','result_similarity',\"Aspiring Human Resources|Seeking Human Resources\")\ndata.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.439649Z","iopub.execute_input":"2022-09-12T03:20:13.440848Z","iopub.status.idle":"2022-09-12T03:20:13.488137Z","shell.execute_reply.started":"2022-09-12T03:20:13.440801Z","shell.execute_reply":"2022-09-12T03:20:13.486850Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# set result_similarity column as label\ny = data['result_similarity']\nx = data.drop(['id','fit','job_title','input','result_similarity'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.489548Z","iopub.execute_input":"2022-09-12T03:20:13.490786Z","iopub.status.idle":"2022-09-12T03:20:13.496457Z","shell.execute_reply.started":"2022-09-12T03:20:13.490749Z","shell.execute_reply":"2022-09-12T03:20:13.495386Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split( x, y,test_size=0.7, random_state=26)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.497594Z","iopub.execute_input":"2022-09-12T03:20:13.498684Z","iopub.status.idle":"2022-09-12T03:20:13.510582Z","shell.execute_reply.started":"2022-09-12T03:20:13.498639Z","shell.execute_reply":"2022-09-12T03:20:13.509407Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"train_baskets = x_train.groupby(['query Id'])['result_similarity_bin'].count().values","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.512015Z","iopub.execute_input":"2022-09-12T03:20:13.512549Z","iopub.status.idle":"2022-09-12T03:20:13.524412Z","shell.execute_reply.started":"2022-09-12T03:20:13.512516Z","shell.execute_reply":"2022-09-12T03:20:13.523331Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"train_baskets ","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.526085Z","iopub.execute_input":"2022-09-12T03:20:13.526430Z","iopub.status.idle":"2022-09-12T03:20:13.545362Z","shell.execute_reply.started":"2022-09-12T03:20:13.526400Z","shell.execute_reply":"2022-09-12T03:20:13.544089Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"!pip install lightgbm==2.2.3 -i https://pypi.tuna.tsinghua.edu.cn/simple","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:13.546767Z","iopub.execute_input":"2022-09-12T03:20:13.547538Z","iopub.status.idle":"2022-09-12T03:20:24.901239Z","shell.execute_reply.started":"2022-09-12T03:20:13.547498Z","shell.execute_reply":"2022-09-12T03:20:24.899822Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"from lightgbm.sklearn import LGBMRanker\nranker = LGBMRanker(\n    objective=\"lambdarank\",\n    metric=\"ndcg\",\n    boosting_type=\"dart\",\n    n_estimators=1,\n    importance_type='gain',\n    verbose=10\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:24.905013Z","iopub.execute_input":"2022-09-12T03:20:24.905563Z","iopub.status.idle":"2022-09-12T03:20:24.914783Z","shell.execute_reply.started":"2022-09-12T03:20:24.905503Z","shell.execute_reply":"2022-09-12T03:20:24.913308Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"ranker = ranker.fit(\n    x_train,\n    y_train,\n    group=train_baskets,\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:24.916973Z","iopub.execute_input":"2022-09-12T03:20:24.917827Z","iopub.status.idle":"2022-09-12T03:20:25.179190Z","shell.execute_reply.started":"2022-09-12T03:20:24.917778Z","shell.execute_reply":"2022-09-12T03:20:25.178158Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"x_test['preds'] = ranker.predict(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:20:25.184033Z","iopub.execute_input":"2022-09-12T03:20:25.185445Z","iopub.status.idle":"2022-09-12T03:20:25.211873Z","shell.execute_reply.started":"2022-09-12T03:20:25.185402Z","shell.execute_reply":"2022-09-12T03:20:25.210862Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# predict the rank based on query Id and prediction\npred_dict = x_test \\\n    .sort_values(['query Id', 'preds'], ascending=False) \\\n    .groupby('query Id')['result_similarity_bin']","metadata":{"execution":{"iopub.status.busy":"2022-09-12T03:30:42.406750Z","iopub.execute_input":"2022-09-12T03:30:42.407277Z","iopub.status.idle":"2022-09-12T03:30:42.416478Z","shell.execute_reply.started":"2022-09-12T03:30:42.407234Z","shell.execute_reply":"2022-09-12T03:30:42.415268Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}