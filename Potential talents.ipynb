{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Potenial talents ranking analysis **","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-04T03:44:58.554595Z","iopub.execute_input":"2022-09-04T03:44:58.555252Z","iopub.status.idle":"2022-09-04T03:44:58.577506Z","shell.execute_reply.started":"2022-09-04T03:44:58.555196Z","shell.execute_reply":"2022-09-04T03:44:58.575870Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/potential-talents/potential-talents - Aspiring human resources - seeking human resources.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:44:59.280405Z","iopub.execute_input":"2022-09-04T03:44:59.281790Z","iopub.status.idle":"2022-09-04T03:44:59.300022Z","shell.execute_reply.started":"2022-09-04T03:44:59.281727Z","shell.execute_reply":"2022-09-04T03:44:59.298693Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:44:59.677588Z","iopub.execute_input":"2022-09-04T03:44:59.678576Z","iopub.status.idle":"2022-09-04T03:44:59.696161Z","shell.execute_reply.started":"2022-09-04T03:44:59.678506Z","shell.execute_reply":"2022-09-04T03:44:59.695060Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"data['input'] = \"Aspiring human resources seeking human resources\"","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:00.035535Z","iopub.execute_input":"2022-09-04T03:45:00.036873Z","iopub.status.idle":"2022-09-04T03:45:00.042540Z","shell.execute_reply.started":"2022-09-04T03:45:00.036826Z","shell.execute_reply":"2022-09-04T03:45:00.041689Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from nltk import word_tokenize, pos_tag\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nimport re \nimport string \ndef removestopwords(text):\n    stop_words = set(stopwords.words('english'))\n#     print(stop_words)\n    text = re.sub(r'[^\\w\\s]', \" \", text)\n    text  = [word for word in text.split() if word not in stop_words]\n    \n    return text    \n\ndef lemmatization(text):\n    words = removestopwords(text)\n#     print(words)\n#     words = word_tokenize(words)\n#     word_tagged = pos_tag(words)\n#     print( word_tagged)\n    lemmatizer = WordNetLemmatizer()\n    text = \" \".join([lemmatizer.lemmatize(word) for word in words])\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:00.384508Z","iopub.execute_input":"2022-09-04T03:45:00.385251Z","iopub.status.idle":"2022-09-04T03:45:00.393182Z","shell.execute_reply.started":"2022-09-04T03:45:00.385213Z","shell.execute_reply":"2022-09-04T03:45:00.392189Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('omw-1.4')","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:00.904105Z","iopub.execute_input":"2022-09-04T03:45:00.904642Z","iopub.status.idle":"2022-09-04T03:45:01.120478Z","shell.execute_reply.started":"2022-09-04T03:45:00.904593Z","shell.execute_reply":"2022-09-04T03:45:01.118899Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"\ndata['job_title'] = data['job_title'].apply(lambda x: lemmatization(x))\ndata['job_title'] ","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:01.377154Z","iopub.execute_input":"2022-09-04T03:45:01.378473Z","iopub.status.idle":"2022-09-04T03:45:01.419546Z","shell.execute_reply.started":"2022-09-04T03:45:01.378412Z","shell.execute_reply":"2022-09-04T03:45:01.418145Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"# **word2vec**","metadata":{}},{"cell_type":"code","source":"import nltk\nimport gensim\nfrom gensim.models import Word2Vec\n","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:02.678226Z","iopub.execute_input":"2022-09-04T03:45:02.679074Z","iopub.status.idle":"2022-09-04T03:45:02.685046Z","shell.execute_reply.started":"2022-09-04T03:45:02.679021Z","shell.execute_reply":"2022-09-04T03:45:02.683862Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"tokens = data['job_title'].apply(lambda x: nltk.word_tokenize(x))\nw2v_model = Word2Vec(tokens,\n                     min_count=1,\n                     window=10,\n                     vector_size=250,\n                     alpha=0.03, \n                     min_alpha=0.0007,\n                     workers = 4,\n                     seed = 42)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:03.337859Z","iopub.execute_input":"2022-09-04T03:45:03.338909Z","iopub.status.idle":"2022-09-04T03:45:03.396077Z","shell.execute_reply.started":"2022-09-04T03:45:03.338856Z","shell.execute_reply":"2022-09-04T03:45:03.394553Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"from scipy import spatial\n    \nindextokey_set = set(w2v_model.wv.index_to_key)\ndef avg_feature_vector(sentence, w2v_model, num_features, index2word_set):\n    words = sentence.split()\n    feature_vec = np.zeros((num_features, ), dtype='float32')\n    n_words = 0\n    for word in words:\n            if word in index2word_set:\n                n_words += 1\n                feature_vec = np.add(feature_vec, w2v_model.wv[word])\n                \n            if (n_words > 0):\n                feature_vec = np.divide(feature_vec, n_words)\n    return feature_vec  ","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:03.599106Z","iopub.execute_input":"2022-09-04T03:45:03.599598Z","iopub.status.idle":"2022-09-04T03:45:03.608159Z","shell.execute_reply.started":"2022-09-04T03:45:03.599552Z","shell.execute_reply":"2022-09-04T03:45:03.607014Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"score1 = []\nfor sentence in data['job_title']:\n    s1_afv = avg_feature_vector(sentence, w2v_model, num_features=250, index2word_set=indextokey_set)     \n    score1.append(s1_afv)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:04.048334Z","iopub.execute_input":"2022-09-04T03:45:04.050008Z","iopub.status.idle":"2022-09-04T03:45:04.061326Z","shell.execute_reply.started":"2022-09-04T03:45:04.049949Z","shell.execute_reply":"2022-09-04T03:45:04.060096Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"score2 = []\nfor sentence in data['input']:\n    s2_afv = [avg_feature_vector(sentence, w2v_model, num_features=250, index2word_set=indextokey_set)]\n    score2.append(s2_afv)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:04.716982Z","iopub.execute_input":"2022-09-04T03:45:04.718001Z","iopub.status.idle":"2022-09-04T03:45:04.726991Z","shell.execute_reply.started":"2022-09-04T03:45:04.717950Z","shell.execute_reply":"2022-09-04T03:45:04.725469Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# the output is Cosine simlilarity with word2vec word embedding \nsim_word2vec = []\nfor i in range(len(score1)):\n    sim = 1 - spatial.distance.cosine(score1[i],score2[i])\n    sim_word2vec.append(sim)\nprint(sim_word2vec)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:04.941981Z","iopub.execute_input":"2022-09-04T03:45:04.942526Z","iopub.status.idle":"2022-09-04T03:45:04.963708Z","shell.execute_reply.started":"2022-09-04T03:45:04.942481Z","shell.execute_reply":"2022-09-04T03:45:04.962266Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"# **TFIDF**","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\ndef cosine_sim(text1, text2):\n    tfidf = vectorizer.fit_transform([text1, text2])\n    return ((tfidf * tfidf.T).A)[0,1]","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:07.807233Z","iopub.execute_input":"2022-09-04T03:45:07.807799Z","iopub.status.idle":"2022-09-04T03:45:07.815778Z","shell.execute_reply.started":"2022-09-04T03:45:07.807750Z","shell.execute_reply":"2022-09-04T03:45:07.814649Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# the output is Cosine simlilarity with tfidf vectorizer \nsim_tfidf = []\nfor i in range(len(data['job_title'])):\n    score = cosine_sim(data['job_title'][i], data['input'][i])\n    sim_tfidf.append(score)\nprint(sim_tfidf)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:08.423773Z","iopub.execute_input":"2022-09-04T03:45:08.425263Z","iopub.status.idle":"2022-09-04T03:45:08.604862Z","shell.execute_reply.started":"2022-09-04T03:45:08.425212Z","shell.execute_reply":"2022-09-04T03:45:08.603656Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"# **Glove**","metadata":{}},{"cell_type":"code","source":"# !wget http://nlp.stanford.edu/data/glove.6B.zip\n# !unzip glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:18.116392Z","iopub.execute_input":"2022-09-04T03:45:18.116970Z","iopub.status.idle":"2022-09-04T03:45:18.124309Z","shell.execute_reply.started":"2022-09-04T03:45:18.116904Z","shell.execute_reply":"2022-09-04T03:45:18.122866Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"GLOVE_EMB = '/kaggle/working/glove.6B.300d.txt'\nEMBEDDING_DIM = 300","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:20.004065Z","iopub.execute_input":"2022-09-04T03:45:20.005639Z","iopub.status.idle":"2022-09-04T03:45:20.011608Z","shell.execute_reply.started":"2022-09-04T03:45:20.005569Z","shell.execute_reply":"2022-09-04T03:45:20.010022Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(data['job_title'])\n\nword_index = tokenizer.word_index\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Vocabulary Size :\", vocab_size)\nword_index.keys()","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:22.304442Z","iopub.execute_input":"2022-09-04T03:45:22.305555Z","iopub.status.idle":"2022-09-04T03:45:22.320392Z","shell.execute_reply.started":"2022-09-04T03:45:22.305490Z","shell.execute_reply":"2022-09-04T03:45:22.319038Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"embeddings_index = {}\n\nf = open(GLOVE_EMB)\nfor line in f:\n  values = line.split()\n  word = value = values[0]\n  coefs = np.asarray(values[1:], dtype='float32')\n  embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' %len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:45:28.058859Z","iopub.execute_input":"2022-09-04T03:45:28.060118Z","iopub.status.idle":"2022-09-04T03:45:53.478430Z","shell.execute_reply.started":"2022-09-04T03:45:28.060069Z","shell.execute_reply":"2022-09-04T03:45:53.477281Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"word_index.keys()","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:43:50.479778Z","iopub.execute_input":"2022-09-04T04:43:50.480290Z","iopub.status.idle":"2022-09-04T04:43:50.488788Z","shell.execute_reply.started":"2022-09-04T04:43:50.480247Z","shell.execute_reply":"2022-09-04T04:43:50.487838Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:51:30.343018Z","iopub.execute_input":"2022-09-04T04:51:30.343583Z","iopub.status.idle":"2022-09-04T04:51:30.354018Z","shell.execute_reply.started":"2022-09-04T04:51:30.343544Z","shell.execute_reply":"2022-09-04T04:51:30.352367Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"embeddings_index.get('human')","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:51:32.825872Z","iopub.execute_input":"2022-09-04T04:51:32.827036Z","iopub.status.idle":"2022-09-04T04:51:32.839399Z","shell.execute_reply.started":"2022-09-04T04:51:32.826990Z","shell.execute_reply":"2022-09-04T04:51:32.837435Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"\nindextokey_set = set(word_index.keys())\nprint(indextokey_set)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:51:34.536006Z","iopub.execute_input":"2022-09-04T04:51:34.536434Z","iopub.status.idle":"2022-09-04T04:51:34.543106Z","shell.execute_reply.started":"2022-09-04T04:51:34.536393Z","shell.execute_reply":"2022-09-04T04:51:34.541466Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"def avg_feature_vector_glove(sentence,embedding_matrix, num_features, index2word_set):\n    words = sentence.split()\n    feature_vec = np.zeros((num_features, ), dtype='float32')\n    n_words = 0\n    for word in words:\n            if word in index2word_set:\n                word_index[word] = i\n                n_words += 1\n                feature_vec = np.add(feature_vec,embedding_matrix[i]) \n            if (n_words > 0):\n                feature_vec = np.divide(feature_vec, n_words)\n    return feature_vec  ","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:55:20.641420Z","iopub.execute_input":"2022-09-04T04:55:20.642864Z","iopub.status.idle":"2022-09-04T04:55:20.653063Z","shell.execute_reply.started":"2022-09-04T04:55:20.642802Z","shell.execute_reply":"2022-09-04T04:55:20.651136Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"\nscore_1 = []\nfor sentence in data['job_title']:\n    s1_afv = avg_feature_vector_glove(sentence,embedding_matrix, num_features=300, index2word_set=indextokey_set)     \n    score_1.append(s1_afv)\nprint(len(score_1))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:55:52.157318Z","iopub.execute_input":"2022-09-04T04:55:52.158195Z","iopub.status.idle":"2022-09-04T04:55:52.167673Z","shell.execute_reply.started":"2022-09-04T04:55:52.158147Z","shell.execute_reply":"2022-09-04T04:55:52.166377Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"score_2 = []\nfor sentence in data['input']:\n    s1_afv = avg_feature_vector_glove(sentence,embedding_matrix, num_features=300, index2word_set=indextokey_set)     \n    score_2.append(s1_afv)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:56:09.153391Z","iopub.execute_input":"2022-09-04T04:56:09.153897Z","iopub.status.idle":"2022-09-04T04:56:09.167850Z","shell.execute_reply.started":"2022-09-04T04:56:09.153860Z","shell.execute_reply":"2022-09-04T04:56:09.166354Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"# the output is Cosine simlilarity with word2vec word embedding \nsim_glove = []\nfor i in range(len(score1)):\n    sim = 1 - spatial.distance.cosine(score_1[i],score_2[i])\n    sim_glove.append(sim)\nprint(sim_glove)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T04:56:14.510559Z","iopub.execute_input":"2022-09-04T04:56:14.511019Z","iopub.status.idle":"2022-09-04T04:56:14.528295Z","shell.execute_reply.started":"2022-09-04T04:56:14.510983Z","shell.execute_reply":"2022-09-04T04:56:14.526987Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"# **Cosine Similarity**","metadata":{}},{"cell_type":"code","source":"# Cosine Similarity with word2vec, tfidf, and glove embedding \nresult_similarity = []\nfor i in range(len(sim_word2vec)):\n    score_mean = (sim_word2vec[i]+sim_tfidf[i]+sim_glove[i])/3\n    result_similarity.append(score_mean)\nprint(result_similarity)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:21:32.638343Z","iopub.execute_input":"2022-09-04T03:21:32.638685Z","iopub.status.idle":"2022-09-04T03:21:32.645953Z","shell.execute_reply.started":"2022-09-04T03:21:32.638655Z","shell.execute_reply":"2022-09-04T03:21:32.644947Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"data['result_similarity'] = result_similarity","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:21:32.647241Z","iopub.execute_input":"2022-09-04T03:21:32.647633Z","iopub.status.idle":"2022-09-04T03:21:32.659793Z","shell.execute_reply.started":"2022-09-04T03:21:32.647549Z","shell.execute_reply":"2022-09-04T03:21:32.658777Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# cut the connection variable as 1,2,3,4, the larger the higher rank \ndata['connection'] = data['connection'].str.split('+').str[0]\ndata['connection'] = data['connection'].astype(int)\nlist = data['connection'].tolist()\nlist.sort()\n# print(list)\ndata['connection'] = pd.cut(data['connection'],[0,40,200,499,600],labels=[1,2,3,4]) \ndata['connection'] = data['connection'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:21:32.661186Z","iopub.execute_input":"2022-09-04T03:21:32.662306Z","iopub.status.idle":"2022-09-04T03:21:32.689606Z","shell.execute_reply.started":"2022-09-04T03:21:32.662256Z","shell.execute_reply":"2022-09-04T03:21:32.688462Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# one hot encoding location variable\ndum_key = pd.get_dummies(data['location'])\ndata = data.drop('location', 1)\ndata = pd.concat([data,dum_key],axis=1)\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:21:32.691057Z","iopub.execute_input":"2022-09-04T03:21:32.691413Z","iopub.status.idle":"2022-09-04T03:21:32.725363Z","shell.execute_reply.started":"2022-09-04T03:21:32.691381Z","shell.execute_reply":"2022-09-04T03:21:32.724186Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# set result_similarity column as label\ny = data['result_similarity']\nx = data.drop(['id','fit','job_title','input','result_similarity'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:21:32.726789Z","iopub.execute_input":"2022-09-04T03:21:32.727181Z","iopub.status.idle":"2022-09-04T03:21:32.735138Z","shell.execute_reply.started":"2022-09-04T03:21:32.727146Z","shell.execute_reply":"2022-09-04T03:21:32.734082Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.4, random_state=26)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:21:32.764218Z","iopub.execute_input":"2022-09-04T03:21:32.764621Z","iopub.status.idle":"2022-09-04T03:21:32.772496Z","shell.execute_reply.started":"2022-09-04T03:21:32.764589Z","shell.execute_reply":"2022-09-04T03:21:32.771356Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Learn to rank has three motheod: Pointwise, Pairwise, and Listwise. As the dataset lable\n# is numerical, we select Pointwise as learn to rank for this task, regression. \nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression().fit(x_train, y_train)\npreds = reg.predict(x_test)\npreds","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:27:42.680647Z","iopub.execute_input":"2022-09-04T03:27:42.681211Z","iopub.status.idle":"2022-09-04T03:27:42.699407Z","shell.execute_reply.started":"2022-09-04T03:27:42.681166Z","shell.execute_reply":"2022-09-04T03:27:42.698384Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluating models**","metadata":{}},{"cell_type":"code","source":"# The regression metric is MSE\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(preds, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T03:27:48.170501Z","iopub.execute_input":"2022-09-04T03:27:48.171280Z","iopub.status.idle":"2022-09-04T03:27:48.179897Z","shell.execute_reply.started":"2022-09-04T03:27:48.171238Z","shell.execute_reply":"2022-09-04T03:27:48.178659Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}